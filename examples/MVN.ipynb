{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import helpers\n",
    "import os\n",
    "os.chdir('../')\n",
    "import torch_vr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 1000\n",
    "d_in = 10\n",
    "d_out = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generates synthetic data\n",
    "U, _, V = torch.svd(torch.randn(N, d_in))\n",
    "Lambda = (10 * torch.ones(d_in)).pow(torch.arange(d_in)/4.5)\n",
    "X = U @ (Lambda * V).T #X.T @ X has eigenvalues Lambda.pow(2)\n",
    "beta = torch.randn(d_in)\n",
    "y = beta @ X.T\n",
    "\n",
    "L = 2*torch.tensor(1e04) # Lipschitz constant of the gradients\n",
    "mu = 2*torch.tensor(1.0) # strong convexity constant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defines the true optimum\n",
    "true_optimum = torch.solve((X.T @ y).unsqueeze(1), X.T @ X)[0].t()\n",
    "\n",
    "# Defines the true mean and covariance of the gaussian posterior\n",
    "true_mean = true_optimum\n",
    "true_cov = (X.T @ X).inverse()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# defines and initializes the model\n",
    "torch.manual_seed(0)\n",
    "\n",
    "layers = list()\n",
    "layers.append(torch.nn.Linear(d_in, d_out, bias=False))\n",
    "activations = list()\n",
    "def squeeze(tensor):\n",
    "    tensor.squeeze(1)\n",
    "activations.append(squeeze) \n",
    "model = torch_vr.Sequential(layers, activations)\n",
    "    \n",
    "# defines the loss\n",
    "loss_func = torch.nn.MSELoss(reduction='sum')\n",
    "\n",
    "# copies the starting point\n",
    "start = model.state_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# runs the non-accelerate algorithms\n",
    "acc_GD = helpers.optimize(X, y, model, loss_func, start, step_size, N, accelerated=False, var_reduce=None)\n",
    "acc_SGD = helpers.optimize(X, y, model, loss_func, start, step_size, batch_size, accelerated=False, var_reduce=None)\n",
    "acc_SAG = helpers.optimize(X, y, model, loss_func, start, step_size, batch_size, accelerated=False, var_reduce='SAG')\n",
    "acc_SAGA = helpers.optimize(X, y, model, loss_func, start, step_size, batch_size, accelerated=False, var_reduce='SAGA')\n",
    "\n",
    "# runs the accelerated algorithms\n",
    "acc_SGD = helpers.optimize(X, y, model, loss_func, start, step_size, batch_size, accelerated=True, var_reduce=None)\n",
    "acc_SAG = helpers.optimize(X, y, model, loss_func, start, step_size, batch_size, accelerated=True, var_reduce='SAG')\n",
    "acc_SAGA = helpers.optimize(X, y, model, loss_func, start, step_size, batch_size, accelerated=True, var_reduce='SAGA')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(L.sqrt() - 1)/(L.sqrt() + 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plots the progress of each of SGD, SAGA, and SAG\n",
    "fig, axes = plt.subplots(1, 2, sharey=True, figsize=(6.6*2,4))\n",
    "\n",
    "axes[0].plot(losses_GD, label='GD')\n",
    "#axes[0].plot(losses_SGD, label='SGD')\n",
    "#axes[0].plot(losses_SAG, label='SAG')\n",
    "#axes[0].plot(losses_SAGA, label='SAGA')\n",
    "#axes[0].legend(loc=\"upper right\");\n",
    "\n",
    "#axes[1].plot(losses_acc_SGD, label='acc_SGD')\n",
    "#axes[1].plot(losses_acc_SAG, label='acc_SAG')\n",
    "#axes[1].plot(losses_acc_SAGA, label='acc_SAGA')\n",
    "#axes[1].legend(loc=\"upper right\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# optimization parameters\n",
    "step_size = 0.1*2.0/(L + mu)\n",
    "batch_size = 16\n",
    "\n",
    "# runs the non-accelerate algorithms\n",
    "nlps_LD = helpers.sample(X, y, model, nlp_func, start, step_size, N, accelerated=False, var_reduce=None, iterations=1000)\n",
    "#nlps_SGD = helpers.sample(X, y, model, nlp_func, start, step_size, batch_size, accelerated=False, var_reduce=None)\n",
    "#nlps_SAG = helpers.sample(X, y, model, nlp_func, start, step_size, batch_size, accelerated=False, var_reduce='SAG')\n",
    "#nlps_SAGA = helpers.sample(X, y, model, nlp_func, start, step_size, batch_size, accelerated=False, var_reduce='SAGA')\n",
    "\n",
    "# runs the accelerated algorithms\n",
    "#gam = torch.sqrt(L + mu)\n",
    "#step_size = mu/(4*gam)\n",
    "gam = 20\n",
    "step_size = 1e-03\n",
    "nlps_acc_LD = helpers.sample(X, y, model, nlp_func, start, step_size, N, accelerated=True, var_reduce=None, gam=gam, iterations=1000)\n",
    "#nlps_acc_SGD = helpers.sample(X, y, model, nlp_func, start, step_size, batch_size, accelerated=True, var_reduce=None, gam=gam)\n",
    "#nlps_acc_SAG = helpers.sample(X, y, model, nlp_func, start, step_size, batch_size, accelerated=True, var_reduce='SAG')\n",
    "#nlps_acc_SAGA = helpers.sample(X, y, model, nlp_func, start, step_size, batch_size, accelerated=True, var_reduce='SAGA', gam=gam)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plots the progress of each of SGD, SAGA, and SAG\n",
    "fig, axes = plt.subplots(1, 2, sharey=True, figsize=(6.6*2,4))\n",
    "\n",
    "axes[0].plot(nlps_LD, label='LD')\n",
    "#axes[0].plot(nlps_SGD[:], label='SGD')\n",
    "#axes[0].plot(nlps_SAG, label='SAG')\n",
    "#axes[0].plot(nlps_SAGA[:], label='SAGA')\n",
    "#axes[0].legend(loc=\"upper right\");\n",
    "\n",
    "axes[1].plot(nlps_acc_LD[:], label='acc_GD')\n",
    "#axes[1].plot(nlps_acc_SGD[:], label='acc_SGD')\n",
    "#axes[1].plot(nlps_acc_SAG, label='acc_SAG')\n",
    "#axes[1].plot(nlps_acc_SAGA[:], label='acc_SAGA')\n",
    "#axes[1].legend(loc=\"upper right\");"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
